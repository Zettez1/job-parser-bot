import asyncio
import logging
import os
from datetime import datetime, time
import aiohttp
from bs4 import BeautifulSoup
from telegram import Bot
import re

# ============= –ù–ê–°–¢–†–û–ô–ö–ò =============
# –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ (–Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –Ω–∞ Render)
BOT_TOKEN = os.getenv("BOT_TOKEN", "8302303298:AAGH3Nllv4JaQRoi8Em8rO1-L_zGinN-gVM")
CHAT_ID = os.getenv("CHAT_ID", "-1003407248691")
SEARCH_TIME = time(hour=7, minute=0)  # 07:00 UTC = 09:00 –ö–∏–µ–≤

# Telegram –∫–∞–Ω–∞–ª—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (–ø—É–±–ª–∏—á–Ω—ã–µ —Å—Å—ã–ª–∫–∏)
TELEGRAM_CHANNELS = [
    "zhitomir9",  # –ñ–∏—Ç–æ–º–∏—Ä –ß–∞—Ç (1 707 —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤)
    "zhytomyr_olx",  # –ü—Ä–∞—Ü–µ–≤–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
]

# =====================================

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)


class JobParser:
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤"""
    
    def __init__(self):
        self.city = "–∂–∏—Ç–æ–º–∏—Ä"
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
        self.keywords = [
            "—Å–≤–∞—Ä—â–∏–∫", "–∑–≤–∞—Ä–Ω–∏–∫", "—Å–≤–∞—Ä—é–≤–∞–ª—å–Ω–∏–∫",
            "—Ä–æ–±–æ—Ç–∞", "—Ä–∞–±–æ—Ç–∞", "—Ä–æ–±–æ—á—ñ", "—Ä–∞–±–æ—á–∏–µ",
            "—à—É–∫–∞—é —Ä–æ–±–æ—Ç—É", "–∏—â—É —Ä–∞–±–æ—Ç—É",
            "—á–æ–ª–æ–≤—ñ–∫", "–º—É–∂—á–∏–Ω–∞", "–ø–∞—Ä–µ–Ω—å", "—Ö–ª–æ–ø–µ—Ü—å"
        ]
        
    async def parse_telegram_preview(self, channel):
        """–ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–µ–≤—å—é Telegram –∫–∞–Ω–∞–ª–∞ —á–µ—Ä–µ–∑ t.me"""
        results = []
        try:
            url = f"https://t.me/s/{channel}"
            
            async with aiohttp.ClientSession() as session:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                }
                async with session.get(url, headers=headers, timeout=15) as response:
                    if response.status == 200:
                        html = await response.text()
                        soup = BeautifulSoup(html, 'html.parser')
                        
                        # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                        messages = soup.find_all('div', class_='tgme_widget_message_text')[:20]
                        
                        for msg in messages:
                            try:
                                text = msg.get_text(strip=True).lower()
                                
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≥–æ—Ä–æ–¥–∞ –∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
                                if self.city in text:
                                    if any(kw in text for kw in self.keywords):
                                        # –ü–æ–ª—É—á–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ
                                        parent = msg.find_parent('div', class_='tgme_widget_message')
                                        if parent:
                                            link_elem = parent.find('a', class_='tgme_widget_message_date')
                                            if link_elem:
                                                link = link_elem.get('href', '')
                                                
                                                # –û–±—Ä–µ–∑–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–µ–≤—å—é
                                                preview = text[:150] + '...' if len(text) > 150 else text
                                                
                                                results.append({
                                                    'name': preview.capitalize(),
                                                    'link': link,
                                                    'source': f'Telegram: @{channel}'
                                                })
                            except Exception as e:
                                logger.debug(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
                                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞–Ω–∞–ª–∞ {channel}: {e}")
            
        return results
    
    async def parse_olx(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ OLX - —Ä–∞–∑–¥–µ–ª —Ä–∞–±–æ—Ç—ã"""
        results = []
        try:
            url = "https://www.olx.ua/d/uk/robota/zhitomir/"
            
            async with aiohttp.ClientSession() as session:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                }
                async with session.get(url, headers=headers, timeout=15) as response:
                    if response.status == 200:
                        html = await response.text()
                        soup = BeautifulSoup(html, 'html.parser')
                        
                        # –ò—â–µ–º –æ–±—ä—è–≤–ª–µ–Ω–∏—è
                        ads = soup.find_all('div', {'data-cy': 'l-card'})[:15]
                        
                        for ad in ads:
                            try:
                                title_elem = ad.find('h6')
                                link_elem = ad.find('a')
                                
                                if title_elem and link_elem:
                                    title = title_elem.get_text(strip=True)
                                    link = link_elem.get('href', '')
                                    
                                    if not link.startswith('http'):
                                        link = 'https://www.olx.ua' + link
                                    
                                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
                                    text_lower = title.lower()
                                    if any(kw in text_lower for kw in self.keywords):
                                        results.append({
                                            'name': title,
                                            'link': link,
                                            'source': 'OLX'
                                        })
                            except Exception as e:
                                logger.debug(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ OLX –∫–∞—Ä—Ç–æ—á–∫–∏: {e}")
                                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ OLX: {e}")
            
        return results
    
    async def parse_rabotaua_lite(self):
        """–ü–æ–ø—ã—Ç–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ Robota.ua (–æ–±–ª–µ–≥—á—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        results = []
        try:
            url = "https://rabota.ua/zapros/zhitomir/%D1%81%D0%B2%D0%B0%D1%80%D1%89%D0%B8%D0%BA"
            
            async with aiohttp.ClientSession() as session:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                }
                async with session.get(url, headers=headers, timeout=10) as response:
                    if response.status == 200:
                        html = await response.text()
                        soup = BeautifulSoup(html, 'html.parser')
                        
                        # –ë–∞–∑–æ–≤—ã–π –ø–æ–∏—Å–∫ —Å—Å—ã–ª–æ–∫ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏–∏
                        links = soup.find_all('a', href=re.compile(r'/company\d+/vacancy\d+'))
                        
                        for link in links[:5]:
                            try:
                                title = link.get_text(strip=True)
                                href = link.get('href', '')
                                
                                if not href.startswith('http'):
                                    href = 'https://rabota.ua' + href
                                
                                if title and len(title) > 10:
                                    results.append({
                                        'name': title,
                                        'link': href,
                                        'source': 'Rabota.ua'
                                    })
                            except Exception as e:
                                logger.debug(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
                                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ Rabota.ua: {e}")
            
        return results
    
    async def parse_workua_lite(self):
        """–ü–æ–ø—ã—Ç–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ Work.ua"""
        results = []
        try:
            url = "https://www.work.ua/jobs-zhytomyr/"
            
            async with aiohttp.ClientSession() as session:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                }
                async with session.get(url, headers=headers, timeout=10) as response:
                    if response.status == 200:
                        html = await response.text()
                        soup = BeautifulSoup(html, 'html.parser')
                        
                        jobs = soup.find_all('div', class_='job-link')
                        
                        for job in jobs[:5]:
                            try:
                                link_elem = job.find('a')
                                if link_elem:
                                    title = link_elem.get_text(strip=True)
                                    link = 'https://www.work.ua' + link_elem.get('href', '')
                                    
                                    results.append({
                                        'name': title,
                                        'link': link,
                                        'source': 'Work.ua'
                                    })
                            except Exception as e:
                                logger.debug(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
                                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ Work.ua: {e}")
            
        return results
    
    async def get_all_candidates(self):
        """–°–æ–±—Ä–∞—Ç—å –≤—Å–µ—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        tasks = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä—Å–∏–Ω–≥ Telegram –∫–∞–Ω–∞–ª–æ–≤
        for channel in TELEGRAM_CHANNELS:
            tasks.append(self.parse_telegram_preview(channel))
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥—Ä—É–≥–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        tasks.extend([
            self.parse_olx(),
            self.parse_rabotaua_lite(),
            self.parse_workua_lite(),
        ])
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        all_candidates = []
        for result in results:
            if isinstance(result, list):
                all_candidates.extend(result)
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ —Å—Å—ã–ª–∫–∞–º
        seen = set()
        unique_candidates = []
        for candidate in all_candidates:
            if candidate['link'] not in seen:
                seen.add(candidate['link'])
                unique_candidates.append(candidate)
        
        return unique_candidates


class TelegramJobBot:
    """Telegram –±–æ—Ç –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    
    def __init__(self, token, chat_id):
        self.token = token
        self.chat_id = chat_id
        self.parser = JobParser()
        
    async def send_daily_report(self):
        """–û—Ç–ø—Ä–∞–≤–∏—Ç—å –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –æ—Ç—á–µ—Ç"""
        logger.info("–ù–∞—á–∏–Ω–∞—é –ø–æ–∏—Å–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤...")
        
        candidates = await self.parser.get_all_candidates()
        
        if not candidates:
            message = f"üîç –ü–æ–∏—Å–∫ —Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤ –≤ –ñ–∏—Ç–æ–º–∏—Ä–µ\n\n"
            message += f"üìÖ {datetime.now().strftime('%d.%m.%Y %H:%M')}\n\n"
            message += "‚ùå –ù–æ–≤—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ\n\n"
            message += "üí° –†–µ–∫–æ–º–µ–Ω–¥—É—é –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—Ä—É—á–Ω—É—é:\n"
            message += "‚Ä¢ t.me/zhitomir9\n"
            message += "‚Ä¢ t.me/zhytomyr_olx\n"
            message += "‚Ä¢ OLX - olx.ua/d/uk/robota/zhitomir/\n"
            message += "‚Ä¢ Work.ua - work.ua/jobs-zhytomyr/"
        else:
            message = f"üîç –ù–∞–π–¥–µ–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {len(candidates)}\n"
            message += f"üìç –ì–æ—Ä–æ–¥: –ñ–∏—Ç–æ–º–∏—Ä\n"
            message += f"üìÖ {datetime.now().strftime('%d.%m.%Y %H:%M')}\n"
            message += f"üë• –ò—â–µ–º: —Å–≤–∞—Ä—â–∏–∫–∏, —Ä–∞–±–æ—á–∏–µ, –º—É–∂—á–∏–Ω—ã 17-50 –ª–µ—Ç\n\n"
            
            for i, candidate in enumerate(candidates, 1):
                message += f"{i}. {candidate['name']}\n"
                message += f"   üîó {candidate['link']}\n"
                message += f"   üì± {candidate['source']}\n\n"
                
                if len(message) > 3500:
                    break
            
            message += "\nüíº –ü–æ–ª–µ–∑–Ω—ã–µ –∫–∞–Ω–∞–ª—ã –∏ —Å–∞–π—Ç—ã:\n"
            message += "‚Ä¢ –ñ–∏—Ç–æ–º–∏—Ä –ß–∞—Ç - t.me/zhitomir9\n"
            message += "‚Ä¢ –ü—Ä–∞—Ü–µ–≤–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è - t.me/zhytomyr_olx\n"
            message += "‚Ä¢ OLX - olx.ua/d/uk/robota/zhitomir/\n"
            message += "‚Ä¢ Work.ua - work.ua/jobs-zhytomyr/"
        
        try:
            bot = Bot(token=self.token)
            await bot.send_message(chat_id=self.chat_id, text=message, disable_web_page_preview=True)
            logger.info("–°–æ–æ–±—â–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")
    
    async def scheduled_task(self):
        """–ó–∞–¥–∞—á–∞ –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é"""
        while True:
            now = datetime.now().time()
            target = SEARCH_TIME
            
            current_seconds = now.hour * 3600 + now.minute * 60 + now.second
            target_seconds = target.hour * 3600 + target.minute * 60
            
            if current_seconds < target_seconds:
                wait_seconds = target_seconds - current_seconds
            else:
                wait_seconds = 86400 - current_seconds + target_seconds
            
            logger.info(f"–°–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ {wait_seconds // 3600} —á {(wait_seconds % 3600) // 60} –º–∏–Ω")
            
            await asyncio.sleep(wait_seconds)
            await self.send_daily_report()
    
    async def run(self):
        """–ó–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞"""
        logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω!")
        logger.info(f"–í—Ä–µ–º—è –æ—Ç–ø—Ä–∞–≤–∫–∏: {SEARCH_TIME}")
        logger.info(f"–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞–Ω–∞–ª–æ–≤: {', '.join(['@' + ch for ch in TELEGRAM_CHANNELS])}")
        
        # –ü–µ—Ä–≤–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ —Å—Ä–∞–∑—É –¥–ª—è —Ç–µ—Å—Ç–∞
        logger.info("–û—Ç–ø—Ä–∞–≤–ª—è—é —Ç–µ—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")
        await self.send_daily_report()
        
        await self.scheduled_task()


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    bot = TelegramJobBot(BOT_TOKEN, CHAT_ID)
    await bot.run()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")